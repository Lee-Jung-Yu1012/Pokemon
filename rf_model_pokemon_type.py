# -*- coding: utf-8 -*-
"""RF_model_Pokemon_type.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YKMJTpRR3CthVD8HrcEk-UALwVgTeOUE

# import


> import package in python
"""

!pip install shap # install shap package

import shap
import pandas as pd # for read files
import seaborn as sns # for draw figure
import matplotlib.pyplot as plt # for draw figure

from sklearn import metrics 
from sklearn.ensemble import RandomForestClassifier 
from sklearn.model_selection import train_test_split # splitting test/train set

from IPython.display import display, HTML # better for export format

"""# Data process

> Pokemon dataset from Kaggle
>
> Aim: Classify **18 main type** of 802 pokemons


---


> Save data as **pandas dataframe** format
>
> 2D array and use column name (feature name) as first index and row (samples) as second index
>
> Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html







"""

url = 'https://raw.githubusercontent.com/su-zu-me/RF_Model_Tutorial/main/Pokemon-classification/pokemon.csv' 
ori_data = pd.read_csv(url) # save ori data and save as "pandas dataframe" format 
data = pd.read_csv(url)   # change some data type

pokemon_info = data[['pokedex_number', 'name', 'type1']]

data.head() # output top5 samples of data

# Example for Dataframe format

print(data['name'], "\n\n")  # show all samples name
print(data['name'][0])    # show first sample (index:0) name

data.dtypes

"""Dataframe.items( )

> Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.items.html
> 
> Iterate over (column name, Samples) pairs.
>
> **label:** The column names for the DataFrame being iterated over.
>
> **content:** (Smaples) The column entries belonging to each label, as a Series.

"""

for label, content in data.items():
  print("label name: ", label, "\n")
  
  print("Smaples of label:")
  print(content, "\n")
  print("-"*50, "\n")

# convert not numeric type to category
for label,content in data.items():
    if not pd.api.types.is_numeric_dtype(content):
        data[label] = data[label].astype('category')

data.dtypes

data.head()

# convert categorical to numeric
for label,content in data.items():
    if pd.api.types.is_categorical_dtype(content):
        data[label] = pd.Categorical(content).codes

# output category code and ori data mapping

# zip: merge multiple array   # Reference: https://www.w3schools.com/python/ref_func_zip.asp
# dict: create array but key cannot duplicate   # Refernce: https://www.w3schools.com/python/python_dictionaries.asp
type1_index_info = dict(zip(data['type1'], ori_data['type1']))
type1_index_info

data.head()

X = data.drop(['pokedex_number', 'name', 'type1', 'classfication'], axis=1) # delete, axis=0 for delete sample, and 1 for column (key) 
y = data['type1'] # only remain type1 data

fea_name_list = list(X.columns) # save feature name list

X_train, X_test, y_train, y_test, pokemon_info_train, pokemon_info_test = train_test_split(X, y, pokemon_info, test_size=0.2)  # split train and test dataset

X_train

y_train

"""# Build Random Forest Model

> Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
>
> RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='auto', min_samples_split=2, min_samples_leaf=1, class_weight=None)
> 

> **important parameters**
>
> *n_estimators:* number of trees
> 
> *bootstrap:* using random sample and size to create each tree
>
> *max_features:* using how many features as candicates to split each node
> 
> *min_samples_split:* if samples size < min_samples_split, stop to split
>
> *min_samples_leaf:* if smaples of leaf node will < min_samples_leaf, stop to split
> 
> *class_weight:* given different weight to each label

"""

rf_model = RandomForestClassifier(n_estimators=500, bootstrap=True, max_features='sqrt', random_state=12) # create random forest model parameters
rf_model.fit(X_train, y_train)  # train model by X_train data

y_pred = rf_model.predict(X_test) # predict X_test

print('Accuracy: ', round(metrics.accuracy_score(y_test, y_pred), 3))  # calculate accuracy
print('MCC: ', round(metrics.matthews_corrcoef(y_test, y_pred), 3))   # calculate mcc

# output error samples

print('{:>5s} {:>12s} {:>12s} {:>12s}'.format('ID', 'Name', 'Predict', 'True'))
print('-'*45)

count = 0
for id, label in y_test.items():  
  if(label != y_pred[count]):   # if predict label not same
    print('{:>5d} {:>12s} {:>12s} {:>12s}'.format(id, ori_data.iloc[id]['name'], type1_index_info[y_pred[count]], type1_index_info[label]))
    error_id_observe_on_shap = id # observe this samples on shap value part
    error_msg_string = ori_data.iloc[id]['name']+" | Predict: "+type1_index_info[y_pred[count]]+", True: "+type1_index_info[label]
  count += 1

"""# Feature importance

> Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_
> 
> The impurity-based feature importances and the higher, the more important the feature.
"""

feature_imp = pd.Series(rf_model.feature_importances_, index=fea_name_list).sort_values(ascending=False)  # get feature importance score and sorting

sns_plot = sns.barplot(x=feature_imp[:20], y=feature_imp.index[:20])  # draw top20 important features
fig = sns_plot.get_figure()
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Visualizing Important Features")
plt.legend()
plt.show()

"""# Shapley Value

> Refernce: https://github.com/slundberg/shap
>
> SHAP (SHapley Additive exPlanations) is a game theoretic approach to **explain the output of any machine learning model**. It connects optimal credit allocation with **local explanations** using the classic Shapley values from game theory and their related extensions
"""

explainer = shap.TreeExplainer(rf_model)  # input rf_model to shap 
shap_values = explainer.shap_values(X_train)  # calculate shap value of X_train

shap.summary_plot(shap_values, X_train, plot_type="bar")  # draw figure

error_data_df = ori_data.iloc[[error_id_observe_on_shap]] 
display(HTML(error_data_df.to_html())) # show error sample

sum_tmp, type1_tmp, df_tmp = ([] for i in range(3)) # initalize list

# calculate shap values
choosen_instance = X.iloc[[error_id_observe_on_shap]] # get error data
shap_values = explainer.shap_values(choosen_instance) # calculate each feature shap value of error sample
error_data_shap_df = pd.DataFrame(shap_values[1],columns=[fea_name_list])
error_data_shap_df.sort_values(by=0, axis=1, ascending=False, inplace=True)

# save value into dataframe for show data
for i in range(18):
  sum_tmp.append(round(shap_values[i].sum(), 3))
  type1_tmp.append(type1_index_info[i])
df_tmp.append(sum_tmp)

# show ori error sample
print(error_msg_string, "\n\nraw data:")
display(HTML(error_data_df.to_html())) 

# show shap value of ori error sample
print("\n\nshap value:")
display(HTML(error_data_shap_df.to_html()))

# show sum of shap value on each type
print("\n\nsum of shap value:")
sum_of_shap_each_type_df = pd.DataFrame(df_tmp, columns=type1_tmp)
sum_of_shap_each_type_df.sort_values(by=0, axis=1, ascending=False, inplace=True)

display(HTML(sum_of_shap_each_type_df.to_html()))
print("\n")

shap.initjs()
shap.force_plot(explainer.expected_value[1], shap_values[1], choosen_instance)